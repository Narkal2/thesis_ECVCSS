{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enquesta Condicions de vida dels usuaris dels CSS\n",
    "# Tratamiento de datos\n",
    "***\n",
    "***\n",
    "## 1. Preprocesado\n",
    "***\n",
    "### 1.1 Carga de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de df_fitxa_llar: (17809, 66)\n",
      "Tamaño de df_q_llar: (6624, 419)\n",
      "Tamaño de df_individus: (12288, 449)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "# Cargar los archivos .sav\n",
    "df_fitxa_llar, meta_fitxa_llar = pyreadstat.read_sav(\"data_raw/848_FITXA_LLAR.sav\")\n",
    "df_q_llar, meta_q_llar = pyreadstat.read_sav(\"data_raw/848_LLAR.sav\")\n",
    "df_individus, meta_individus = pyreadstat.read_sav(\"data_raw/848_INDIVIDUS.sav\")\n",
    "\n",
    "# Mostrar las primeras filas de cada DataFrame para inspección\n",
    "with open(\"data_preprocess/1_variables_inicials.txt\", \"w\") as f:\n",
    "\n",
    "    f.write(\"848_FITXA_LLAR.sav\\n\")\n",
    "    f.write(str(df_fitxa_llar.columns.tolist()))\n",
    "\n",
    "    f.write(\"\\n\\n848_LLAR.sav\\n\")\n",
    "    f.write(str(df_q_llar.columns.tolist()))\n",
    "\n",
    "    f.write(\"\\n\\n848_INDIVIDUS.sav\\n\")\n",
    "    f.write(str(df_individus.columns.tolist()))\n",
    "\n",
    "print(f\"Tamaño de df_fitxa_llar: {df_fitxa_llar.shape}\")\n",
    "print(f\"Tamaño de df_q_llar: {df_q_llar.shape}\")\n",
    "print(f\"Tamaño de df_individus: {df_individus.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba para extraer información de los metadatos. Peta en un datetime, pero se puede explorar mejor en caso de necesitarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "# Función personalizada para serializar objetos que no son compatibles con JSON, como datetime\n",
    "def custom_serializer(obj):\n",
    "    if isinstance(obj, (datetime.date, datetime.datetime)):\n",
    "        return obj.isoformat()  # Convertir a formato ISO 8601\n",
    "    raise TypeError(f\"Tipo no serializable: {type(obj)}\")\n",
    "\n",
    "# Guardar los metadatos como JSON\n",
    "with open(\"data_raw/fitxa_llar.json\", \"w\") as file:\n",
    "    json.dump(meta_fitxa_llar.__dict__, file, default=custom_serializer, indent=4)\n",
    "\n",
    "with open(\"data_raw/q_llar.json\", \"w\") as file:\n",
    "    json.dump(meta_q_llar.__dict__, file, default=custom_serializer, indent=4)\n",
    "\n",
    "with open(\"data_raw/individus.json\", \"w\") as file:\n",
    "    json.dump(meta_individus.__dict__, file, default=custom_serializer, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.2 Selección de variables\n",
    "\n",
    "Se seleccionan las variables relevantes, eliminando aquellas que no interesan para el análisis. Se han limpiado a mano del primer campo del json con metadatos (`columns_names_to_labels`) y aquí se procesan para tener las versiones con las variables a utilizar finalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def list_variables(json_file: dict):\n",
    "    return list(json_file['column_names_to_labels'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Fitxa Llar ----: \n",
      "['IDENT_LL', 'IDENT', 'MEMBRE', 'DIST', 'BARRI', 'CSS', 'F9', 'F9PROV', 'F9PAIS1', 'F9PAIS2', 'F10', 'F13', 'F14', 'F13R', 'F11_12', 'INGRESSOS_EQUIVALENTS', 'TAXA60', 'TAXA40', 'TAXA30']\n",
      "\n",
      "---- Questionari Llar ----: \n",
      "['IDENT_LL', 'IDENT', 'L20A1_1', 'L20A2_1', 'L20A1_2', 'L20A2_2', 'L20A1_3', 'L20A2_3', 'L21A', 'L21B', 'L22_3', 'L22_5', 'L24_1', 'L24_2', 'L48_1', 'L48_3', 'L49A', 'L49B', 'L49C', 'L49D', 'L53A1_1', 'L53A1_2', 'L53A1_3', 'L53A1_95', 'L53A1_98', 'L53A1_99', 'L53A2', 'L54', 'L48_2R', 'L23R', 'L20A1_8R', 'L20A1_6R', 'L20A1_4R', 'L20A1_5R', 'L22_1R', 'L22_2R', 'L22_4R', 'L22_6R', 'L22_7R', 'L50R', 'L52R', 'LP05_R1', 'LP06', 'LP01', 'L1_R1', 'HY010N', 'HY010G', 'HY020']\n",
      "\n",
      "---- Individus ----: \n",
      "['IDENT_LL', 'IDENT', 'PERS_REF', 'P1', 'P2', 'P3', 'P35', 'P35_COD', 'P36H_1', 'P36M_1', 'P36H_2', 'P36M_2', 'P36H_3', 'P36M_3', 'P36H_4', 'P36M_4', 'P36H_5', 'P36M_5', 'P36H_6', 'P36M_6', 'P36H_7', 'P36M_7', 'P36H_8', 'P36M_8', 'P36H_9', 'P36M_9', 'P36H_10', 'P36M_10', 'P36H_11', 'P36M_11', 'P75_1', 'P75_2', 'P75_3', 'P75_4', 'P75_5', 'P75_6', 'P75_7', 'P75_8', 'P85', 'P86_1', 'P86_2', 'P86_3', 'P86_4', 'P86_5', 'P87', 'VISITA_CSS', 'P88_1', 'P88_2', 'P88_3', 'P88_4', 'P88_5', 'P88_6', 'P88_8', 'P88_9', 'P88_10', 'P88_11', 'P88_12', 'P88_98', 'P88_99', 'P88_COD', 'P89_1', 'P89_2', 'P89_3', 'P89_4', 'P89_5', 'P89_6', 'P89_7', 'P89_9', 'P89_10', 'P89_98', 'P89_99', 'P89_COD', 'P90A_1', 'P90A_2', 'P90A_3', 'P90A_4', 'P90B_1', 'P90B_2', 'P90B_3', 'P90B_4', 'P90B_5', 'P90B_6', 'P90B_7', 'P90B_8', 'P90C_1', 'P90C_2', 'P90C_3', 'P90C_4', 'P91', 'P92', 'P93_1', 'P93_2', 'P93_3', 'P93_4', 'P93_5', 'P93_6', 'P93_7', 'FINAL_1', 'FINAL_2', 'FINAL_3', 'FINAL_4', 'OBS', 'P1_R1', 'P85R', 'F7', 'F8G', 'F8R1', 'F8R2', 'P2_R1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitxa Llar\n",
    "with open(\"data_preprocess/select_fitxa_llar.json\", 'r', encoding='utf-8') as file:\n",
    "    select_fitxa_llar = json.load(file)\n",
    "variables_fitxa_llar = list_variables(select_fitxa_llar)\n",
    "print(f\"---- Fitxa Llar ----: \\n{variables_fitxa_llar}\\n\")\n",
    "\n",
    "# Questionari Llar\n",
    "with open(\"data_preprocess/select_q_llar.json\", 'r', encoding='utf-8') as file:\n",
    "    select_q_llar = json.load(file)\n",
    "variables_q_llar = list_variables(select_q_llar)\n",
    "print(f\"---- Questionari Llar ----: \\n{variables_q_llar}\\n\")\n",
    "\n",
    "# Individus\n",
    "with open(\"data_preprocess/select_individus.json\", 'r', encoding='utf-8') as file:\n",
    "    select_individus = json.load(file)\n",
    "variables_individus = list_variables(select_individus)\n",
    "print(f\"---- Individus ----: \\n{variables_individus}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitxa_llar = df_fitxa_llar.filter(variables_fitxa_llar, axis='columns')\n",
    "df_q_llar = df_q_llar.filter(variables_q_llar, axis='columns')\n",
    "df_individus = df_individus.filter(variables_individus, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de metadatos JSON\n",
    "\n",
    "Se genera un nuevo JSON que contiene unicamente los campos relativos a las variables seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def clean_json(json_file: dict):\n",
    "    variables = set(json_file['column_names_to_labels'].keys())\n",
    "    if 'variable_value_labels' in json_file:\n",
    "        json_file['variable_value_labels'] = {k: v for k, v in json_file['variable_value_labels'].items() if k in variables}\n",
    "    if 'variable_measure' in json_file:\n",
    "        json_file['variable_measure'] = {k: v for k, v in json_file['variable_measure'].items() if k in variables}\n",
    "    if 'readstat_variable_types' in json_file:\n",
    "        json_file['readstat_variable_types'] = {k: v for k, v in json_file['readstat_variable_types'].items() if k in variables}\n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitxa Llar\n",
    "with open(\"data_preprocess/select_fitxa_llar.json\", 'r', encoding='utf-8') as file:\n",
    "    select_fitxa_llar = json.load(file)\n",
    "clean_fitxa_llar = clean_json(select_fitxa_llar)\n",
    "with open('data_final/clean_fitxa_llar.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(clean_fitxa_llar, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Questionari Llar\n",
    "with open(\"data_preprocess/select_q_llar.json\", 'r', encoding='utf-8') as file:\n",
    "    select_q_llar = json.load(file)\n",
    "clean_q_llar = clean_json(select_q_llar)\n",
    "with open('data_final/clean_q_llar.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(clean_q_llar, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Individus\n",
    "with open(\"data_preprocess/select_individus.json\", 'r', encoding='utf-8') as file:\n",
    "    select_individus = json.load(file)\n",
    "clean_individus = clean_json(select_individus)\n",
    "with open('data_final/clean_individus.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(clean_individus, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de df_fitxa_llar: (17809, 19)\n",
      "Tamaño de df_q_llar: (6624, 48)\n",
      "Tamaño de df_individus: (12288, 109)\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas de cada DataFrame para inspección\n",
    "with open(\"data_preprocess/2_variables_truncades.txt\", \"w\") as f:\n",
    "\n",
    "    f.write(\"848_FITXA_LLAR.sav\\n\")\n",
    "    f.write(str(df_fitxa_llar.columns.tolist()))\n",
    "\n",
    "    f.write(\"\\n\\n848_LLAR.sav\\n\")\n",
    "    f.write(str(df_q_llar.columns.tolist()))\n",
    "\n",
    "    f.write(\"\\n\\n848_INDIVIDUS.sav\\n\")\n",
    "    f.write(str(df_individus.columns.tolist()))\n",
    "\n",
    "print(f\"Tamaño de df_fitxa_llar: {df_fitxa_llar.shape}\")\n",
    "print(f\"Tamaño de df_q_llar: {df_q_llar.shape}\")\n",
    "print(f\"Tamaño de df_individus: {df_individus.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedimiento antiguo (eliminar variables con lista)\n",
    "\n",
    "Para ir iterando en el proceso selección de variables se iban añadiendo a la lista aquellas que no eran relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitxa_llar_eliminar = ['ENTREVISTADOR', 'IDIOMA', 'COND_LEG_1', 'COND_LEG_2_1', 'COND_LEG_3_1', 'COND_LEG_4_1', 'COND_LEG_5_1', 'COND_LEG_5_1_1', 'COND_LEG_5_1_2', 'COND_LEG_5_1_3', 'COND_LEG_5_1_4', 'COND_LEG_5_1_5', 'COND_LEG_5_1_6', \n",
    "#                        'COND_LEG_6_1', 'PESAIXINDIV1', 'PESMOSINDIV1', 'PESAIXINDIV2', 'PESMOSINDIV2', 'PESAIXINDIV3', 'PESMOSINDIV3', 'F0A1', 'F0A2', 'F0', 'F2', 'F3', 'F4A1', 'F4A2', 'F5', 'F6', 'F7', 'F8A1', 'F8A2',\n",
    "#                        'F11', 'F12', 'F15', 'F16A1_1', 'F16A1_2', 'F16A1_3', 'F16A1_4', 'F16A1_95', 'F16A1_96', 'F16A1_98', 'F16A1_99', 'F16A2', 'F8G', 'F8R1', 'F8R3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_llar_eliminar = ['ENTREVISTADOR', 'REGISTRO', 'FECHAINI', 'HORAINI', 'FECHAFIN', 'HORAFIN', 'IDIOMA', 'COND_LEG_1', 'COND_LEG_2_1', 'COND_LEG_3_1', 'COND_LEG_4_1', 'COND_LEG_5_1', 'COND_LEG_5_1_1', 'COND_LEG_5_1_2', 'COND_LEG_5_1_3', \n",
    "#                     'COND_LEG_5_1_4', 'COND_LEG_5_1_5', 'COND_LEG_5_1_6', 'COND_LEG_6_1', 'PESLLAR_AIX1', 'PESLLAR_MOS1', 'PESLLAR_AIX2', 'PESLLAR_MOS2', 'PESLLAR_AIX3', 'PESLLAR_MOS3', 'PROXY', 'PROXI', 'L1TEXT', \n",
    "#                     'L2A1', 'L2A2', 'L3', 'L4A1', 'L4A2', 'L5', 'L6A1', 'L6A2', 'L7', 'L8', 'L9A1', 'L9A2', 'L10A1_1', 'L10A2_1', 'L10A2TEXT_1', 'L10A3_1', 'L10A3TEXT_1', 'L10A1_2', 'L10A2_2', 'L10A2TEXT_2', 'L10A3_2', 'L10A3TEXT_2', 'L10A1_3', \n",
    "#                     'L10A2_3', 'L10A2TEXT_3', 'L10A3_3', 'L10A3TEXT_3', 'L10A1_4', 'L10A2_4', 'L10A2TEXT_4', 'L10A3_4', 'L10A3TEXT_4', 'L10A1_5', 'L10A2_5', 'L10A2TEXT_5', 'L10A3_5', 'L10A3TEXT_5', 'L10A1_6', 'L10A2_6', 'L10A2TEXT_6', 'L10A3_6', \n",
    "#                     'L10A3TEXT_6', 'L10A1_7', 'L10A2_7', 'L10A2TEXT_7', 'L10A3_7', 'L10A3TEXT_7', 'L11A1', 'L11A2', 'L12A1', 'L12A2', 'L13A1', 'L13A2', 'L14A1_1', 'L14A2_1', 'L14A3_1', 'L14A3TEXT_1', 'L14A4_1', 'L14A4TEXT_1', 'L14A1_2', 'L14A2_2', \n",
    "#                     'L14A3_2', 'L14A3TEXT_2', 'L14A4_2', 'L14A4TEXT_2', 'L14A1_3', 'L14A2_3', 'L14A3_3', 'L14A3TEXT_3', 'L14A4_3', 'L14A4TEXT_3', 'L14A1_4', 'L14A2_4', 'L14A3_4', 'L14A3TEXT_4', 'L14A4_4', 'L14A4TEXT_4', 'L14A1_5', 'L14A2_5', \n",
    "#                     'L14A3_5', 'L14A3TEXT_5', 'L14A4_5', 'L14A4TEXT_5', 'L14A1_6', 'L14A2_6', 'L14A3_6', 'L14A3TEXT_6', 'L14A4_6', 'L14A4TEXT_6', 'L14A1_7', 'L14A2_7', 'L14A3_7', 'L14A3TEXT_7', 'L14A4_7', 'L14A4TEXT_7', 'L15A1', 'L15A2', 'L16A1', \n",
    "#                     'L16A2', 'L17A1_1', 'L17A2_1', 'L17A2TEXT_1', 'L17A3_1', 'L17A3TEXT_1', 'L17A1_2', 'L17A2_2', 'L17A2TEXT_2', 'L17A3_2', 'L17A3TEXT_2', 'L17A1_3', 'L17A2_3', 'L17A2TEXT_3', 'L17A3_3', 'L17A3TEXT_3', 'L17A1_4', 'L17A2_4', 'L17A2TEXT_4', \n",
    "#                     'L17A3_4', 'L17A3TEXT_4', 'L17A1_5', 'L17A2_5', 'L17A2TEXT_5', 'L17A3_5', 'L17A3TEXT_5', 'L17A1_6', 'L17A2_6', 'L17A2TEXT_6', 'L17A3_6', 'L17A3TEXT_6', 'L17A1_7', 'L17A2_7', 'L17A2TEXT_7', 'L17A3_7', 'L17A3TEXT_7', 'L18', 'L19A', \n",
    "#                     'L19ATEXT', 'L19B', 'L19BTEXT', 'L19C', 'L19CTEXT', 'L25', 'L26A1_1', 'L26A2_1', 'L26B_1', 'L26C_1', 'L26D1_1', 'L26D2_1', 'L26PRE', 'L26A1_2', 'L26A2_2', 'L26B_2', 'L26C_2', 'L26D1_2', 'L26D2_2', 'L26PRE2', 'L26A1_3', 'L26A2_3', \n",
    "#                     'L26B_3', 'L26C_3', 'L26D1_3', 'L26D2_3', 'L27', 'L28A1', 'L28A2', 'L29', 'L30', 'L31A1', 'L31A2', 'L32', 'L33A', 'L33ATEXT', 'L33B', 'L33BTEXT', 'L33C', 'L33CTEXT', 'L34', 'L35A', 'L35ATEXT', 'L35B', 'L35BTEXT', 'L35C', 'L35CTEXT', \n",
    "#                     'L36', 'L37A', 'L37ATEXT', 'L37B', 'L37BTEXT', 'L37C', 'L37CTEXT', 'L38', 'L39A', 'L39ATEXT', 'L39B', 'L39BTEXT', 'L39C', 'L39CTEXT', 'L40', 'L41A', 'L41ATEXT', 'L41B', 'L41BTEXT', 'L41C', 'L41CTEXT', 'L42', 'L43A_1', 'L43ATEXT_1', \n",
    "#                     'L43B_1', 'L43BTEXT_1', 'L43C_1', 'L43CTEXT_1', 'L43D_1', 'L43E_1', 'L43ETEXT_1', 'L43PRE', 'L43A_2', 'L43ATEXT_2', 'L43B_2', 'L43BTEXT_2', 'L43C_2', 'L43CTEXT_2', 'L43D_2', 'L43E_2', 'L43ETEXT_2', 'L43PRE2', 'L43A_3', 'L43ATEXT_3', \n",
    "#                     'L43B_3', 'L43BTEXT_3', 'L43C_3', 'L43CTEXT_3', 'L43D_3', 'L43E_3', 'L43ETEXT_3', 'L44', 'L45', 'L46', 'L46TEXT', 'L47', 'L51A1', 'L51A2', 'L55A', 'L55B', 'L55C', 'L55D', 'L55E', 'L55F', 'L55G', 'L55H', 'L55I','L56', 'L57A1', \n",
    "#                     'L57A2', 'OBS', 'LP04', 'LP05', 'LH01', 'LH01G', 'LH01R', 'LH01R2', 'LH02', \n",
    "#                     'HY100G', 'HY100N', 'HY030N', 'HY030G', 'HY040G', 'HY040N', 'HY060N', 'HY060G', 'PHY090G', 'PHY090N', 'HY070N', 'HY070G', 'HY080N', 'HY080G', 'HY110G', 'HY110N', 'HY131N', 'HY131G', 'HY130N', 'HY130G', 'HY120N', 'HY120G', 'PY010G', \n",
    "#                     'PY010N', 'PY021G', 'PY021N', 'PY020G', 'PY020N', 'PY035G', 'PY035N', 'PY050G', 'PY050N', 'PY080G', 'PY080N', 'PY090G', 'PY090N', 'PY100G', 'PY100N', 'PY110G', 'PY110N', 'PY120G', 'PY120N', 'PY130G', 'PY130N', 'PY140G', 'PY140N', \n",
    "#                     'PY150G', 'PY150N', 'PHY050G', 'PHY050N', 'HY145N', 'HY140', 'HY025', 'HY002', 'HY001',\n",
    "#                     'DIST', 'BARRI', 'TAXA60', 'TAXA40', 'TAXA30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individus_eliminar = ['ESTUDIO', 'ENTREVISTADOR', 'REGISTRO', 'FECHAINI', 'HORAINI', 'FECHAFIN', 'HORAFIN', 'IDIOMA', 'PESAIXINDIV1', 'PESMOSINDIV1', 'PESAIXINDIV2', 'PESMOSINDIV2', 'PESAIXINDIV3', 'PESMOSINDIV3',\n",
    "#                       'CONTESTA', 'MOTIU', 'MOTIU_COD', 'PROXY', 'PROXI', 'COND_LEG_1', 'COND_LEG_2_1', 'COND_LEG_3_1', 'COND_LEG_4_1', 'COND_LEG_5_1', 'COND_LEG_5_1_1', 'COND_LEG_5_1_2', 'COND_LEG_5_1_3', 'COND_LEG_5_1_4', 'COND_LEG_5_1_5', \n",
    "#                       'COND_LEG_5_1_6', 'COND_LEG_6_1', 'P1_COD', 'P2_O', 'P4_1', 'P4_2', 'P4_3', 'P4_98', 'P4_99', 'P4_1_COD', 'P4_2_COD', 'P4_3_COD', 'P5_0', 'P5_1', 'P5_2', 'P5_3', 'P6_1', 'P6_2', 'P7', 'P7_COD', 'P8_1', 'P8_2', 'P9', 'P10_1', \n",
    "#                       'P10_2', 'P10_3', 'P11', 'P12', 'P13_1', 'P13_2', 'P13_3', 'P13_4', 'P13_5', 'P14_1', 'P14_2', 'P14_3', 'P14_4', 'P14_5', 'P14_6', 'P15_1', 'P16_1', 'P16_2', 'P17_1', 'P17_2', 'P17_3', 'P18', 'P18_COD', 'P19', 'P19_COD', 'P20_1', \n",
    "#                       'P20_2', 'P20_3', 'P20_4', 'P20_98', 'P20_99', 'P20_COD', 'P21_1', 'P21_2', 'P22', 'P23_1', 'P23_2', 'P23_3', 'P24', 'P24_COD', 'P25', 'P26', 'P26_O', 'P27_1', 'P27_1_O', 'P27_2', 'P27_2_O', 'P27_3', 'P27_3_O', 'P27_4', 'P27_4_O', \n",
    "#                       'P27_5', 'P27_5_O', 'P27_6', 'P27_6_O', 'P27_7', 'P27_7_O', 'P27_8', 'P27_8_O', 'P27_9', 'P27_9_O', 'P27_10', 'P27_10_O', 'P27_11', 'P27_11_O', 'P27_12', 'P27_12_O', 'P28', 'P29', 'P29_O', 'P30_1', 'P30_1_O', 'P30_2', 'P30_2_O', \n",
    "#                       'P30_3', 'P30_3_O', 'P30_4', 'P30_4_O', 'P30_5', 'P30_5_O', 'P30_6', 'P30_6_O', 'P31', 'P32_1', 'P32_2', 'P33', 'P33_COD', 'P34', 'P34_COD', 'P37', 'P38', 'P39A_1', 'P39B_1', 'P39_1X', 'P39A_2', 'P39B_2', 'P39_2X', 'P39A_3', 'P39B_3', \n",
    "#                       'P39_3X', 'P40A', 'P40A_COD', 'P40B', 'P40C', 'P40D', 'P41_1', 'P41_2', 'P41_3', 'P41_4', 'P41_5', 'P41_6', 'P41_7', 'P41_8', 'P41_COD', 'P42', 'P43A_1', 'P43B_1', 'P43_1X', 'P43A_2', 'P43B_2', 'P43_2X', 'P43A_3', 'P43B_3', 'P43_3X', \n",
    "#                       'P44', 'P45', 'P46', 'P47', 'P48', 'P49', 'P50_1', 'P50A', 'P50_2', 'P50B', 'P50_98', 'P50_99', 'P51', 'P52', 'P53', 'P54_1', 'P54_2', 'P55', 'P56', 'P57', 'P58', 'P59', 'P60', 'P61', 'P62', 'P62_COD', 'P63', 'P64_1', 'P64_2', 'P64_3', \n",
    "#                       'P64_4', 'P65', 'P66', 'P67', 'P68', 'P69', 'P70', 'P71', 'P72', 'P73', 'P74', 'P76A_1', 'P76A_1_COD', 'P76B_1', 'P76B_1_O', 'P76C_1', 'P76D_1', 'P76E_1', 'P76F_1', 'P76_1X', 'P76A_2', 'P76A_2_COD', 'P76B_2', 'P76B_2_O', 'P76C_2', \n",
    "#                       'P76D_2', 'P76E_2', 'P76F_2', 'P76_2X', 'P76A_3', 'P76A_3_COD', 'P76B_3', 'P76B_3_O', 'P76C_3', 'P76D_3', 'P76E_3', 'P76F_3', 'P76_3X', 'P76A_4', 'P76A_4_COD', 'P76B_4', 'P76B_4_O', 'P76C_4', 'P76D_4', 'P76E_4', 'P76F_4', 'P76_4X', \n",
    "#                       'P76A_5', 'P76A_5_COD', 'P76B_5', 'P76B_5_O', 'P76C_5', 'P76D_5', 'P76E_5', 'P76F_5', 'P77', 'P78A_1', 'P78B_1', 'P78C_1', 'P78D_1', 'P78E_1', 'P78_X', 'P78A_2', 'P78B_2', 'P78C_2', 'P78D_2', 'P78E_2', 'P79', 'P80_1', 'P80_2', 'P81', \n",
    "#                       'P82', 'P83', 'P84_2', 'P14_1R', 'P14_2R', 'P6', 'P17', 'P23', 'LT012', 'PY010N', 'PY010G', 'PY021N', 'PY021G', 'PY020N', 'PY020G', 'PY035G', 'PY035N', 'PY050G', 'PY050N', 'PY080G', 'PY080N', 'PY090G', 'PY090N', 'PY100G', 'PY100N', \n",
    "#                       'PY110G', 'PY110N', 'PY120G', 'PY120N', 'PY130G', 'PY130N', 'PY140G', 'PY140N', 'PY150G', 'PY150N', 'PHY050G', 'PHY050N', 'TAXA60', 'TAXA40', 'TAXA30', 'L50R', 'L52R', 'F11_12', 'F13', 'F14', 'DIST', 'BARRI',\n",
    "#                       # Estas son las recodificadas (que ya se añaden en q_llar!!):\n",
    "#                       'L48_2R', 'L23R', 'L20A1_8R', 'L20A1_6R', 'L20A1_4R', 'L20A1_5R', 'L22_1R', 'L22_2R', 'L22_4R', 'L22_6R', 'L22_7R', 'LP01',\n",
    "#                       # Otras:\n",
    "#                       'MES', 'ANY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fitxa_llar = df_fitxa_llar.drop(fitxa_llar_eliminar, axis='columns')\n",
    "# df_q_llar = df_q_llar.drop(q_llar_eliminar, axis='columns')\n",
    "# df_individus = df_individus.drop(individus_eliminar, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.3 Cambio a los valores reales de las variables\n",
    "\n",
    "Se utilizan los campos de los metadatos (`variable_value_labels`) para cambiar los códigos de respuesta por su significado real. Así se convierten los números en strings para la mayoría de variables, que en realidad son categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_final/clean_fitxa_llar.json\", 'r', encoding='utf-8') as file:\n",
    "    metadata_fitxa_llar = json.load(file)\n",
    "value_labels = metadata_fitxa_llar['variable_value_labels']\n",
    "for var in value_labels.keys():\n",
    "    if var in df_fitxa_llar.columns and var in value_labels:\n",
    "        df_fitxa_llar[var] = df_fitxa_llar[var].map(lambda x: value_labels[var].get(str(x), x))\n",
    "\n",
    "with open(\"data_final/clean_q_llar.json\", 'r', encoding='utf-8') as file:\n",
    "    metadata_q_llar = json.load(file)\n",
    "value_labels = metadata_q_llar['variable_value_labels']\n",
    "for var in value_labels.keys():\n",
    "    if var in df_q_llar.columns and var in value_labels:\n",
    "        df_q_llar[var] = df_q_llar[var].map(lambda x: value_labels[var].get(str(x), x))\n",
    "\n",
    "with open(\"data_final/clean_individus.json\", 'r', encoding='utf-8') as file:\n",
    "    metadata_individus = json.load(file)\n",
    "value_labels = metadata_individus['variable_value_labels']\n",
    "for var in value_labels.keys():\n",
    "    if var in df_individus.columns and var in value_labels:\n",
    "        df_individus[var] = df_individus[var].map(lambda x: value_labels[var].get(str(x), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.4 Unión de las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Tamaño del DataFrame combinado resultante ----\n",
      "(6624, 172)\n"
     ]
    }
   ],
   "source": [
    "# Primer paso: Unir df_fitxa_llar y df_q_llar usando 'IDENT_LL' y 'IDENT'\n",
    "df_llar_merged = pd.merge(df_fitxa_llar, df_q_llar, on=['IDENT_LL', 'IDENT'], how='inner')\n",
    "\n",
    "# Segundo paso: Unir df_llar_merged con df_individus usando 'IDENT_LL' y 'IDENT'\n",
    "df = pd.merge(df_llar_merged, df_individus, on=['IDENT_LL', 'IDENT'], how='inner')\n",
    "\n",
    "# Verificar el tamaño del DataFrame final\n",
    "print(\"\\n---- Tamaño del DataFrame combinado resultante ----\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método para ver en que columnas compartidas entre tablas existen valores diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Identificar columnas duplicadas que han generado sufijos '_x' y '_y'\n",
    "columnas_x_y = [col for col in df.columns if col.endswith('_x') or col.endswith('_y')]\n",
    "\n",
    "# Paso 4: Comparar las columnas que tienen el mismo nombre pero con sufijos '_x' y '_y'\n",
    "for col in columnas_x_y:\n",
    "    col_base = col[:-2]  # Obtiene el nombre base de la columna sin el sufijo\n",
    "    if col_base + '_x' in df.columns and col_base + '_y' in df.columns:\n",
    "        # Compara si los valores de las columnas son iguales\n",
    "        if df[col_base + '_x'].equals(df[col_base + '_y']):\n",
    "            # Si son iguales, elimina una de las dos (mantiene solo '_x' o '_y')\n",
    "            df = df.drop(columns=[col_base + '_y'])\n",
    "            df = df.rename(columns={col_base + '_x': col_base})\n",
    "        else:\n",
    "            # Si no son iguales, puedes dejar ambas o inspeccionar los datos manualmente\n",
    "            print(f'Valores diferentes en la columna: {col_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_preprocess/3_variables_merged.txt\", \"w\") as f:\n",
    "    f.write(\"Variables del df resultante:\\n\")\n",
    "    f.write(str(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.5 Renombrar variables\n",
    "\n",
    "En un json externo se ha realizado un mapeo del nombre original de las variables con el nuevo nombre para poder identificarlas de manera correcta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data_preprocess/map_variables.json', 'r') as json_file:\n",
    "    column_mapping = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_preprocess/4_variables_renombradas.txt\", \"w\") as f:\n",
    "    f.write(\"Variables del df resultante:\\n\")\n",
    "    f.write(str(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data_preprocess/processed_df.pkl')\n",
    "df.to_csv('data_preprocess/processed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.6 Limpieza Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_pickle('data_preprocess/processed_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de valores nulos:\n",
      "                     Variable  Nulos  Porcentaje Nulos\n",
      "0             Prov_Nacimiento   2876             43.42\n",
      "1            Pais1_Nacimiento   3748             56.58\n",
      "2                     Conyuge   1708             25.79\n",
      "3                N_Hijos_Llar   2852             43.06\n",
      "4          Lavadora_Asequible   6257             94.46\n",
      "5                TV_Asequible   6330             95.56\n",
      "6          Telefono_Asequible   6576             99.28\n",
      "7                 ONG_Caritas   2808             42.39\n",
      "8               ONG_Creu_Roja   2808             42.39\n",
      "9           ONG_Banc_Aliments   2808             42.39\n",
      "10                  ONG_Otras   2808             42.39\n",
      "11                     ONG_NS   2808             42.39\n",
      "12                     ONG_NC   2808             42.39\n",
      "13                 Tiempo_ONG   2808             42.39\n",
      "14      Minutos_Limpieza_Ropa   1163             17.56\n",
      "15    Minutos_Limpieza_Cocina   1159             17.50\n",
      "16      Minutos_Limpieza_Casa   1214             18.33\n",
      "17            Minutos_Cocinar   1166             17.60\n",
      "18       Minutos_Comprar_Alim   1246             18.81\n",
      "19       Minutos_Reparaciones   3283             49.56\n",
      "20       Minutos_Admin_Dinero   2424             36.59\n",
      "21  Minutos_Atencion_Ancianos   5809             87.70\n",
      "22  Minutos_Atencion_Discapac   5816             87.80\n",
      "23  Minutos_Atencion_Enfermos   5868             88.59\n",
      "24   Minutos_Atencion_Menores   4182             63.13\n",
      "25       Prestacio_Maternitat   5381             81.23\n",
      "26        Prestacio_Jubilacio   5381             81.23\n",
      "27             Prestacio_Atur   5381             81.23\n",
      "28      Indemnizacion_Despido   5381             81.23\n"
     ]
    }
   ],
   "source": [
    "# Análisis de valores nulos por variable\n",
    "nulos_por_variable = df.isnull().sum()\n",
    "porcentaje_nulos = (df.isnull().mean() * 100).round(2)\n",
    "\n",
    "# Crear un DataFrame con el resumen de valores nulos\n",
    "resumen_nulos = pd.DataFrame({\n",
    "    \"Variable\": df.columns,\n",
    "    \"Nulos\": nulos_por_variable,\n",
    "    \"Porcentaje Nulos\": porcentaje_nulos\n",
    "}).query(\"Nulos > 1000\").reset_index(drop=True)\n",
    "\n",
    "print(\"Resumen de valores nulos:\")\n",
    "print(resumen_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se rellenan con un '0' las variables numéricas que tienen valor nulo cuando debería ser valor '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['N_Hijos_Llar'] = df['N_Hijos_Llar'].fillna(0)\n",
    "\n",
    "# Nos deshacemos de las variables de Minutos\n",
    "variables_minutos = [\"Minutos_Limpieza_Ropa\", \"Minutos_Limpieza_Cocina\", \"Minutos_Limpieza_Casa\", \"Minutos_Cocinar\", \n",
    "                     \"Minutos_Comprar_Alim\", \"Minutos_Reparaciones\", \"Minutos_Admin_Dinero\", \"Minutos_Atencion_Ancianos\", \n",
    "                     \"Minutos_Atencion_Discapac\", \"Minutos_Atencion_Enfermos\", \"Minutos_Atencion_Menores\"]\n",
    "df = df.drop(variables_minutos, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las variables que tienen más de un 90% de valores nulos: 'Lavadora_Asequible', 'TV_Asequible', 'Telefono_Asequible'. De hecho, las otras de asequible también tienen muchos valores nulos, y no aportan más valor que las de disponible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Lavadora_Asequible', 'TV_Asequible', 'Telefono_Asequible'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observaciones generales\n",
    "\n",
    "- **31 casos**: Si `Propietat_Habitatge` == `Habitació col·lectiu`, tiene valores nulos en todas las respuestas de electrodomesticos\n",
    "- **129 casos**: Valores nulos en estudios, situación laboralm, tareas domesticas y prestaciones.\n",
    "- **408 casos**: Valores nulos en respuestas con feedback de serveis socials.\n",
    "\n",
    "En la variable `Observaciones` de alguna de ellas, se comenta porque no está respondida la mayor parte de la entrevista. Estos casos habría que eliminarlos??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.7 Creación nuevas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_pais_nacimiento(row):\n",
    "    if pd.notna(row['Prov_Nacimiento']):\n",
    "        return \"España\"\n",
    "    # elif row['Pais1_Nacimiento'] == \"Altres\":      #TODO: Revisar, los strings de Pais2_Nacimiento no son correctos.\n",
    "    #     return row['Pais2_Nacimiento'].capitalize()\n",
    "    else:\n",
    "        return row['Pais1_Nacimiento']\n",
    "\n",
    "# Crear la nueva columna\n",
    "df['Pais_Nacimiento'] = df.apply(generar_pais_nacimiento, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determinar_tipo_hogar(conyuge, hijos):\n",
    "    if conyuge == \"Sí\" and hijos == 0:\n",
    "        return \"Pareja sin hijos\"\n",
    "    elif conyuge == \"Sí\" and hijos > 0:\n",
    "        return \"Pareja con hijos\"\n",
    "    elif conyuge == \"No\" and hijos == 0:\n",
    "        return \"Persona sin hijos\"\n",
    "    elif conyuge == \"No\" and hijos > 0:\n",
    "        return \"Persona con hijos\"\n",
    "    else:\n",
    "        return None  # Por si acaso hay valores inesperados\n",
    "\n",
    "df['Tipo_Hogar'] = df.apply(lambda row: determinar_tipo_hogar(row['Conyuge_Recod'], row['N_Hijos_Llar']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Tipo_Hogar2             Tipo_Hogar3\n",
      "0  Pare o mare amb fills/es (sense altres persones)  Monoparental con hijos\n",
      "1      Parella amb fills/es (sense altres persones)        Pareja con hijos\n",
      "2  Pare o mare amb fills/es (sense altres persones)  Monoparental con hijos\n",
      "3                                       Unipersonal             Unipersonal\n",
      "4                                       Unipersonal             Unipersonal\n"
     ]
    }
   ],
   "source": [
    "nuevo_tipo_hogar_values = {\n",
    "    'Unipersonal' : 'Unipersonal', \n",
    "    'Dues o més persones sense nucli' : 'Dos o más núcleos', \n",
    "    'Parella sense fills/es (sense altres persones)' : 'Pareja sin hijos',\n",
    "    'Parella sense fills/es (amb altres persones)' : 'Pareja sin hijos',\n",
    "    'Parella amb fills/es (sense altres persones)' : 'Pareja con hijos',\n",
    "    'Parella amb fills/es (amb altres persones)' : 'Pareja con hijos',\n",
    "    'Pare o mare amb fills/es (sense altres persones)' : 'Monoparental con hijos',\n",
    "    'Pare o mare amb fills/es (amb altres persones)' : 'Monoparental con hijos',\n",
    "    'Dos o més nuclis' : 'Dos o más núcleos'\n",
    "}\n",
    "\n",
    "# Recodificar y crear la nueva variable \"Tipo_Hogar3\"\n",
    "df[\"Tipo_Hogar3\"] = df[\"Tipo_Hogar2\"].map(nuevo_tipo_hogar_values)\n",
    "\n",
    "# Verificar el resultado (opcional)\n",
    "print(df[[\"Tipo_Hogar2\", \"Tipo_Hogar3\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Edad Edad_Recod2\n",
      "0  49.0     45 - 64\n",
      "1  31.0     16 - 44\n",
      "2  38.0     16 - 44\n",
      "3  54.0     45 - 64\n",
      "4  87.0    85 i més\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Definir los límites (bins) y las etiquetas\n",
    "# Usamos 15 como límite inferior para que, al incluir el límite más bajo, se asignen correctamente a partir de 16.\n",
    "bins = [0, 44, 64, 74, 84, np.inf]\n",
    "etiquetas = [\"16 - 44\", \"45 - 64\", \"65 - 74\", \"75 - 84\", \"85 i més\"]\n",
    "\n",
    "# Crear la nueva variable recodificada.\n",
    "# Se asume que la columna 'Edad' existe y contiene valores numéricos.\n",
    "df[\"Edad_Recod2\"] = pd.cut(df[\"Edad\"],\n",
    "                          bins=bins,\n",
    "                          labels=etiquetas,\n",
    "                          right=True,           # Los límites superiores se incluyen (excepto el primer intervalo si no se usa include_lowest)\n",
    "                          include_lowest=True)    # Asegura que el límite inferior se incluya en el primer bin\n",
    "\n",
    "# Verifica el resultado:\n",
    "print(df[[\"Edad\", \"Edad_Recod2\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos algunos valores de las variables con horas de dedicación, para poder considerarlas como variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista de variables de tiempo\n",
    "variables_tiempo = [\"Horas_Limpieza_Ropa\", \"Horas_Limpieza_Cocina\",  \"Horas_Limpieza_Casa\", \"Horas_Cocinar\",\n",
    "                    \"Horas_Comprar_Alim\", \"Horas_Reparaciones\", \"Horas_Admin_Dinero\"] \n",
    "\n",
    "for variable in variables_tiempo:\n",
    "    # Convertir valores específicos a 0\n",
    "    df[variable] = df[variable].replace(\"No s hi dedica\", 0)\n",
    "    # Asegurar que la columna sea numérica\n",
    "    df[variable] = pd.to_numeric(df[variable], errors='coerce').fillna(0)\n",
    "\n",
    "#\"No en té la necessitat\" !!Para el caso de Atencion a colectivos puede ser util....\n",
    "variables_atencion = [\"Horas_Atencion_Ancianos\", \"Horas_Atencion_Discapac\", \"Horas_Atencion_Enfermos\", \"Horas_Atencion_Menores\"]\n",
    "\n",
    "for variable in variables_atencion:\n",
    "    # Convertir valores específicos a 0\n",
    "    df[variable] = df[variable].replace(\"No en té la necessitat\", 0)\n",
    "    # Asegurar que la columna sea numérica\n",
    "    df[variable] = pd.to_numeric(df[variable], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables de tareas domésticas\n",
    "domestic_tasks = [\n",
    "    'Horas_Limpieza_Ropa', \n",
    "    'Horas_Limpieza_Cocina', \n",
    "    'Horas_Limpieza_Casa'\n",
    "    # 'Horas_Cocinar', \n",
    "    # 'Horas_Comprar_Alim', \n",
    "    # 'Horas_Reparaciones', \n",
    "    # 'Horas_Admin_Dinero'\n",
    "]\n",
    "\n",
    "# Lista de variables de tareas de cuidados\n",
    "care_tasks = [\n",
    "    'Horas_Atencion_Ancianos', \n",
    "    'Horas_Atencion_Discapac', \n",
    "    'Horas_Atencion_Enfermos',  \n",
    "    'Horas_Atencion_Menores'\n",
    "]\n",
    "\n",
    "# Crear la nueva variable 'Horas_Domesticas' sumando las columnas de tareas domésticas\n",
    "df['Horas_Domesticas'] = df[domestic_tasks].sum(axis=1)\n",
    "\n",
    "# Crear la nueva variable 'Horas_Cuidados' sumando las columnas de tareas de cuidados\n",
    "df['Horas_Cuidados'] = df[care_tasks].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables de valoración\n",
    "variables_valoracion = [\n",
    "    \"Valoracion_General\", \"Valoracion_TiempoEspera\", \"Valoracion_Facilidad\",\n",
    "    \"Valoracion_Horarios\", \"Valoracion_Utilidad\", \"Valoracion_Dedicacion\",\n",
    "    \"Valoracion_Intervencion\", \"Valoracion_Respuesta\", \"Valoracion_Profesionalidad\",\n",
    "    \"Valoracion_Comprension\", \"Valoracion_Amabilidad\", \"Valoracion_Intimidad\",\n",
    "    \"Valoracion_Utilidad2\", \"Valoracion_Gestion\", \"Valoracion_Amabilidad2\",\n",
    "    \"Valoracion_Intimidad2\", \"Millora_Autonomia\", \"Millora_Anim\",\n",
    "    \"Sentimient_Companyia\", \"Sentimient_Tranquilitat\", \"Sentimient_Seguretat\",\n",
    "    \"Satisfaccio_Vital\", \"Benefici_Familia\"\n",
    "]\n",
    "\n",
    "# Reemplazar valores específicos por códigos numéricos\n",
    "valores_a_reemplazar = {\"No ho sap\": 98, \"No contesta\": 99}\n",
    "\n",
    "for variable in variables_valoracion:\n",
    "    # Reemplazar valores no numéricos por los códigos correspondientes\n",
    "    df[variable] = df[variable].replace(valores_a_reemplazar)\n",
    "    # Asegurar que la columna sea numérica\n",
    "    df[variable] = pd.to_numeric(df[variable], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener en cuenta que en estas variables de valoración numéricas aparecerán valores 98 y 99. Filtrar cuando se tengan que utilizar!! Se podría buscar un método para interpolar valores intermedios, pero no hay tantos valores nulos como para que valga la pena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.8 Eliminación variables no relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los paises han quedado capturados en la nueva variable 'Pais_Nacimiento'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Pais1_Nacimiento', 'Pais2_Nacimiento'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Membresía' y 'Parentesco' no tienen sentido al filtrar solo por la persona responsable de la llar. Igual para Persona de Referencia. Conyuge está mejor en la recodificada (se renombra a esa misma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Membresia_Llar', 'Parentesco', 'Conyuge', 'Persona_Referencia'], axis=1)\n",
    "df = df.rename(columns={\"Conyuge_Recod\": \"Conyuge\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con Nivel de estudios recodificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Nivel_Estudios'], axis=1)\n",
    "df = df.rename(columns={\"Nivel_Estudios_Recod\": \"Nivel_Estudios\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También eliminamos los identificadores, que no tienen interés para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ID_Hogar', 'ID_Individuo'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a revisar valores nulos y acabar de eliminar algunas variables que no nos serán de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de valores nulos:\n",
      "                 Variable  Nulos  Porcentaje Nulos\n",
      "0         Prov_Nacimiento   2876             43.42\n",
      "1             ONG_Caritas   2808             42.39\n",
      "2           ONG_Creu_Roja   2808             42.39\n",
      "3       ONG_Banc_Aliments   2808             42.39\n",
      "4               ONG_Otras   2808             42.39\n",
      "5                  ONG_NS   2808             42.39\n",
      "6                  ONG_NC   2808             42.39\n",
      "7              Tiempo_ONG   2808             42.39\n",
      "8    Prestacio_Maternitat   5381             81.23\n",
      "9     Prestacio_Jubilacio   5381             81.23\n",
      "10         Prestacio_Atur   5381             81.23\n",
      "11  Indemnizacion_Despido   5381             81.23\n"
     ]
    }
   ],
   "source": [
    "# Análisis de valores nulos por variable\n",
    "nulos_por_variable = df.isnull().sum()\n",
    "porcentaje_nulos = (df.isnull().mean() * 100).round(2)\n",
    "\n",
    "# Crear un DataFrame con el resumen de valores nulos\n",
    "resumen_nulos = pd.DataFrame({\n",
    "    \"Variable\": df.columns,\n",
    "    \"Nulos\": nulos_por_variable,\n",
    "    \"Porcentaje Nulos\": porcentaje_nulos\n",
    "}).query(\"Nulos > 500\").reset_index(drop=True)\n",
    "\n",
    "print(\"Resumen de valores nulos:\")\n",
    "print(resumen_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables referentes a ONG concretas tienen demasiados valores nulos, y quedan recogidas en `Acudio_ONG` recodificada. Lo mismo para las referentes a prestaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ONG_Caritas', 'ONG_Creu_Roja', 'ONG_Banc_Aliments', 'ONG_Otras', 'ONG_NS', 'ONG_NC', 'ONG_Otras2', 'Tiempo_ONG'], axis=1)\n",
    "df = df.drop(['Prestacio_Maternitat', 'Prestacio_Jubilacio', 'Prestacio_Atur', 'Indemnizacion_Despido'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_final/5_variables_finales.txt\", \"w\") as f:\n",
    "    f.write(\"Variables del df resultante:\\n\")\n",
    "    f.write(str(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.9 Cambio de tipología de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de tipologias de variables\n",
    "nuevas_tipologias = {\n",
    "    \"ID_Hogar\": \"float\",\n",
    "    \"ID_Individuo\": \"float\",\n",
    "    # \"Distrito\": \"category\",\n",
    "    # \"Barrio\": \"category\",\n",
    "    # \"Centro_CSS\": \"category\",\n",
    "    # \"Lugar_Nacimiento\": \"category\",\n",
    "    # \"Prov_Nacimiento\": \"category\",\n",
    "    # \"Estado_Civil\": \"category\",\n",
    "    # \"Conyuge\": \"category\",\n",
    "    \"N_Hijos_Llar\": \"float\",  # Puede ser int si garantizamos que no hay decimales\n",
    "    \"Ingresos_Equivalentes\": \"float\",\n",
    "    # \"Riesgo_Pobreza_60\": \"category\",\n",
    "    # \"Riesgo_Pobreza_40\": \"category\",\n",
    "    # \"Riesgo_Pobreza_30\": \"category\",\n",
    "    # \"Propietat_Habitatge\": \"category\",\n",
    "    # \"Lavadora_Disponible\": \"category\",\n",
    "    # \"Vater_Disponible\": \"category\",\n",
    "    # \"Ducha_Disponible\": \"category\",\n",
    "    # \"Goteras_Humedades\": \"category\",\n",
    "    # \"Escasez_Luz_Natural\": \"category\",\n",
    "    # \"Mala_Ventilacion\": \"category\",\n",
    "    # \"Grietas_Paredes\": \"category\",\n",
    "    # \"Problemas_Estructura\": \"category\",\n",
    "    # \"Insectos_Ratas\": \"category\",\n",
    "    # \"Ruido_Vecinos\": \"category\",\n",
    "    # \"Temp_Caliente_Invierno\": \"category\",\n",
    "    # \"Contaminacion_Medioambiental\": \"category\",\n",
    "    # \"Delincuencia_Vandalismo\": \"category\",\n",
    "    # \"Vacaciones_Anual\": \"category\",\n",
    "    # \"Comida_DosDias\": \"category\",\n",
    "    # \"Gasto_Imprevisto_800\": \"category\",\n",
    "    # \"Mora_Hipoteca\": \"category\",\n",
    "    # \"Mora_Prestamos\": \"category\",\n",
    "    # \"Mora_Alquiler\": \"category\",\n",
    "    # \"Mora_Servicios\": \"category\",\n",
    "    # \"Fin_De_Mes\": \"category\",\n",
    "    # \"Acudio_ONG\": \"category\",\n",
    "    # \"Fin_De_Mes_Recod\": \"category\",\n",
    "    # \"Acudio_ONG_Recod\": \"category\",\n",
    "    \"Renda_Neta_Llar\": \"float\",\n",
    "    \"Renda_Bruta_Llar\": \"float\",\n",
    "    \"Renda_Total_Llar\": \"float\",\n",
    "    #\"Persona_Referencia\": \"float\",  # Asumiendo un identificador único\n",
    "    # \"Nivel_Estudios\": \"category\", # Pasa a ser la recodificada\n",
    "    # \"Situacion_Laboral\": \"category\",\n",
    "    # \"Categoria_Profesional\": \"category\",\n",
    "    # \"Tareas_Domesticas\": \"category\",\n",
    "    # \"Tareas_Domesticas_Otros\": \"category\",\n",
    "    \"Horas_Limpieza_Ropa\": \"float\",\n",
    "    #\"Minutos_Limpieza_Ropa\": \"float\",\n",
    "    \"Horas_Limpieza_Cocina\": \"float\",\n",
    "    #\"Minutos_Limpieza_Cocina\": \"float\",\n",
    "    \"Horas_Limpieza_Casa\": \"float\",\n",
    "    #\"Minutos_Limpieza_Casa\": \"float\",\n",
    "    \"Horas_Cocinar\": \"float\",\n",
    "    #\"Minutos_Cocinar\": \"float\",\n",
    "    \"Horas_Comprar_Alim\": \"float\",\n",
    "    #\"Minutos_Comprar_Alim\": \"float\",\n",
    "    \"Horas_Reparaciones\": \"float\",\n",
    "    #\"Minutos_Reparaciones\": \"float\",\n",
    "    \"Horas_Admin_Dinero\": \"float\",\n",
    "    #\"Minutos_Admin_Dinero\": \"float\",\n",
    "    \"Horas_Atencion_Ancianos\": \"float\",\n",
    "    #\"Minutos_Atencion_Ancianos\": \"float\",\n",
    "    \"Horas_Atencion_Discapac\": \"float\",\n",
    "    #\"Minutos_Atencion_Discapac\": \"float\",\n",
    "    \"Horas_Atencion_Enfermos\": \"float\",\n",
    "    #\"Minutos_Atencion_Enfermos\": \"float\",\n",
    "    \"Horas_Atencion_Menores\": \"float\",\n",
    "    #\"Minutos_Atencion_Menores\": \"float\",\n",
    "    # \"Prestacion_Desempleo\": \"category\",\n",
    "    # \"Prestacion_Jubilacion\": \"category\",\n",
    "    # \"Prestacion_Supervivencia\": \"category\",\n",
    "    # \"Prestacion_Proteccion\": \"category\",\n",
    "    # \"Prestacion_Enfermedad\": \"category\",\n",
    "    # \"Prestacion_Invalidez\": \"category\",\n",
    "    # \"Prestacion_Escolar\": \"category\",\n",
    "    # \"Prestacion_Otros\": \"category\",\n",
    "    # \"Estado_Salud\": \"category\",\n",
    "    # \"Nerviosismo\": \"category\",\n",
    "    # \"Desanimo\": \"category\",\n",
    "    # \"Tranquilidad\": \"category\",\n",
    "    # \"Tristeza\": \"category\",\n",
    "    # \"Felicidad\": \"category\",\n",
    "    # \"Problemas_Salud\": \"category\",\n",
    "    # \"Visita_CSS\": \"category\",\n",
    "    # \"Visita_CSS_Econom\": \"category\",\n",
    "    # \"Visita_CSS_Familia\": \"category\",\n",
    "    # \"Visita_CSS_Depend\": \"category\",\n",
    "    # \"Visita_CSS_Empleo\": \"category\",\n",
    "    # \"Visita_CSS_Vivienda\": \"category\",\n",
    "    # \"Visita_CSS_Otros\": \"category\",\n",
    "    # \"Visita_CSS_Psico\": \"category\",\n",
    "    # \"Visita_CSS_Salud\": \"category\",\n",
    "    # \"Visita_CSS_Juridico\": \"category\",\n",
    "    # \"Visita_CSS_Aliment\": \"category\",\n",
    "    # \"Visita_CSS_ViolGenero\": \"category\",\n",
    "    # \"Visita_CSS_NS\": \"category\",\n",
    "    # \"Visita_CSS_NC\": \"category\",\n",
    "    # \"Conoc_CSS_Boca\": \"category\",\n",
    "    # \"Conoc_CSS_OAC\": \"category\",\n",
    "    # \"Conoc_CSS_Web\": \"category\",\n",
    "    # \"Conoc_CSS_Ayunt\": \"category\",\n",
    "    # \"Conoc_CSS_ServPubl\": \"category\",\n",
    "    # \"Conoc_CSS_ORG\": \"category\",\n",
    "    # \"Conoc_CSS_Otros\": \"category\",\n",
    "    # \"Conoc_CSS_Proxim\": \"category\",\n",
    "    # \"Conoc_CSS_Iniciativa\": \"category\",\n",
    "    # \"Conoc_CSS_NS\": \"category\",\n",
    "    # \"Conoc_CSS_NC\": \"category\",\n",
    "    # \"Conoc_CSS_Otros2\": \"category\",\n",
    "    \"Valoracion_General\": \"float\",\n",
    "    \"Valoracion_TiempoEspera\": \"float\",\n",
    "    \"Valoracion_Facilidad\": \"float\",\n",
    "    \"Valoracion_Horarios\": \"float\",\n",
    "    \"Valoracion_Utilidad\": \"float\",\n",
    "    \"Valoracion_Dedicacion\": \"float\",\n",
    "    \"Valoracion_Intervencion\": \"float\",\n",
    "    \"Valoracion_Respuesta\": \"float\",\n",
    "    \"Valoracion_Profesionalidad\": \"float\",\n",
    "    \"Valoracion_Comprension\": \"float\",\n",
    "    \"Valoracion_Amabilidad\": \"float\",\n",
    "    \"Valoracion_Intimidad\": \"float\",\n",
    "    \"Valoracion_Utilidad2\": \"float\",\n",
    "    \"Valoracion_Gestion\": \"float\",\n",
    "    \"Valoracion_Amabilidad2\": \"float\",\n",
    "    \"Valoracion_Intimidad2\": \"float\",\n",
    "    # \"Recomend_CSS\": \"category\",\n",
    "    # \"Participacion_Decision\": \"category\",\n",
    "    \"Millora_Autonomia\": \"float\",\n",
    "    \"Millora_Anim\": \"float\",\n",
    "    \"Sentimient_Companyia\": \"float\",\n",
    "    \"Sentimient_Tranquilitat\": \"float\",\n",
    "    \"Sentimient_Seguretat\": \"float\",\n",
    "    \"Satisfaccio_Vital\": \"float\",\n",
    "    # \"Benefici_Familia\": \"category\",\n",
    "    # \"Observaciones\": \"object\",  # Texto libre\n",
    "    # \"Nivel_Estudios_Recod\": \"category\",\n",
    "    # \"Estado_Salud_Recod\": \"category\",\n",
    "    # \"Sexo\": \"category\",\n",
    "    \"Edad\": \"float\",\n",
    "    \"Membres_Llar\": \"float\"\n",
    "    # \"Edad_Recod\": \"category\",\n",
    "    # \"Segment_Gen_Edad\": \"category\",\n",
    "    # \"Relacio_Activitat_Recod\": \"category\",\n",
    "    # \"Pais_Nacimiento\": \"category\",\n",
    "    # \"Tipo_Hogar\": \"category\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertencia: La columna ID_Hogar no existe en el DataFrame.\n",
      "Advertencia: La columna ID_Individuo no existe en el DataFrame.\n",
      "Tipos de datos después de la conversión:\n",
      "Distrito              object\n",
      "Barrio                object\n",
      "Centro_CSS            object\n",
      "Lugar_Nacimiento      object\n",
      "Prov_Nacimiento       object\n",
      "                      ...   \n",
      "Tipo_Hogar            object\n",
      "Tipo_Hogar3           object\n",
      "Edad_Recod2         category\n",
      "Horas_Domesticas     float64\n",
      "Horas_Cuidados       float64\n",
      "Length: 143, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convertir los tipos de datos\n",
    "for columna, tipo in nuevas_tipologias.items():\n",
    "    try:\n",
    "        # Comprobar si la columna es válida en el DataFrame\n",
    "        if columna in df.columns:\n",
    "            if tipo == \"category\":\n",
    "                df[columna] = df[columna].astype(\"category\")\n",
    "            elif tipo == \"int\":\n",
    "                df[columna] = pd.to_numeric(df[columna], errors=\"coerce\").astype(\"Int64\")\n",
    "            elif tipo == \"float\":\n",
    "                df[columna] = pd.to_numeric(df[columna], errors=\"coerce\")\n",
    "        else:\n",
    "            print(f\"Advertencia: La columna {columna} no existe en el DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la columna {columna}: {e}\")\n",
    "\n",
    "# Verificar los tipos de datos después de la conversión\n",
    "print(\"Tipos de datos después de la conversión:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos Ingresos_Equivalentes, porque da errores la variable... Si es necesaria revisar más adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['Ingresos_Equivalentes'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.10 Guardado de datos finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo JSON guardado en: data_final/variables_finales.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def export_variable_types_to_json(df, output_file):\n",
    "    \"\"\"\n",
    "    Separa las variables del DataFrame en numéricas y categóricas,\n",
    "    asignando a cada una un tipo simplificado (e.g. \"int\", \"float\", \"categorical\")\n",
    "    y escribe esta información en un archivo JSON.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): El DataFrame a analizar.\n",
    "        output_file (str): Ruta y nombre del archivo JSON de salida.\n",
    "    \"\"\"\n",
    "    numeric_types = {}\n",
    "    categorical_types = {}\n",
    "    \n",
    "    for col, dtype in df.dtypes.items():\n",
    "        # Para variables numéricas\n",
    "        if pd.api.types.is_numeric_dtype(dtype):\n",
    "            if pd.api.types.is_integer_dtype(dtype):\n",
    "                numeric_types[col] = \"int\"\n",
    "            elif pd.api.types.is_float_dtype(dtype):\n",
    "                numeric_types[col] = \"float\"\n",
    "            else:\n",
    "                # Por si hubiera otro tipo numérico\n",
    "                numeric_types[col] = str(dtype)\n",
    "        # Para variables categóricas: consideramos tanto object como categorical\n",
    "        elif pd.api.types.is_object_dtype(dtype) or isinstance(dtype, pd.CategoricalDtype):\n",
    "            categorical_types[col] = \"categorical\"\n",
    "        # Si quisieras incluir otros tipos, podrías agregarlos aquí.\n",
    "    \n",
    "    # Construir el diccionario final\n",
    "    data = {\n",
    "        \"numericas\": numeric_types,\n",
    "        \"categoricas\": categorical_types\n",
    "    }\n",
    "    \n",
    "    # Escribir en el archivo JSON con una indentación de 4 espacios para mayor legibilidad.\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    \n",
    "    print(f\"Archivo JSON guardado en: {output_file}\")\n",
    "\n",
    "export_variable_types_to_json(df, \"data_final/variables_finales.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data_final/final_df.pkl')\n",
    "df.to_csv('data_final/final_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doctorado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
